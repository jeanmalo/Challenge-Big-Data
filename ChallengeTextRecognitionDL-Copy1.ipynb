{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge TextRecognition Apprentissage Profond\n",
    "Auteur : JMLD - AD - CN\n",
    "Date : 30/01/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gensim\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "import zipfile\n",
    "import collections\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cible    object\n",
       "Mot1     object\n",
       "Mot2     object\n",
       "Mot3     object\n",
       "Mot4     object\n",
       "Mot5     object\n",
       "Mot6     object\n",
       "Mot7     object\n",
       "Mot8     object\n",
       "Mot9     object\n",
       "Mot10    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = \"../IntroductionDL/\"\n",
    "trainf = \"calldesk-intents.txt\"\n",
    "dataf = datapath + trainf\n",
    "train = pd.read_csv(dataf,names=['Cible','Mot1','Mot2','Mot3','Mot4','Mot5','Mot6','Mot7','Mot8','Mot9','Mot10'],dtype=str,delim_whitespace=True)\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)  # %(asctime)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(size=200, sg=1, alpha=0.05, window=5, batch_words=1000, min_count=1, workers=2, negative=10, iter=10)\n",
    "sentences = gensim.models.word2vec.LineSentence(new)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences)\n",
    "model.save('../Models/' + new.split('/')[2].split('.')[0] + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(size=200, sg=1, alpha=0.05, window=5, batch_words=1000, min_count=1, workers=2, negative=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = gensim.models.word2vec.LineSentence('calldesk-intents.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 342 word types from a corpus of 6687 raw words and 800 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : min_count=1 retains 342 unique words (100% of original 342, drops 0)\n",
      "INFO : min_count=1 leaves 6687 word corpus (100% of original 6687, drops 0)\n",
      "INFO : deleting the raw counts dictionary of 342 items\n",
      "INFO : sample=0.001 downsamples 56 most-common words\n",
      "INFO : downsampling leaves estimated 2586 word corpus (38.7% of prior 6687)\n",
      "INFO : estimated required memory for 342 words and 200 dimensions: 718200 bytes\n",
      "INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : training model with 2 workers on 342 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5\n",
      "INFO : expecting 800 sentences, matching count from corpus used for vocabulary survey\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : training on 66870 raw words (25848 effective words) took 0.2s, 156736 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25848"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2Vec object under ./calldesk-intents-model, separately None\n",
      "INFO : not storing attribute syn0norm\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved ./calldesk-intents-model\n"
     ]
    }
   ],
   "source": [
    "model.save('./' + 'calldesk-intents-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cible</th>\n",
       "      <th>Mot1</th>\n",
       "      <th>Mot2</th>\n",
       "      <th>Mot3</th>\n",
       "      <th>Mot4</th>\n",
       "      <th>Mot5</th>\n",
       "      <th>Mot6</th>\n",
       "      <th>Mot7</th>\n",
       "      <th>Mot8</th>\n",
       "      <th>Mot9</th>\n",
       "      <th>Mot10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confirm</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Confirm</td>\n",
       "      <td>absolument</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Confirm</td>\n",
       "      <td>ah</td>\n",
       "      <td>oui</td>\n",
       "      <td>ça</td>\n",
       "      <td>c</td>\n",
       "      <td>est</td>\n",
       "      <td>bien</td>\n",
       "      <td>ça</td>\n",
       "      <td>comme</td>\n",
       "      <td>ça</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confirm</td>\n",
       "      <td>aller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Confirm</td>\n",
       "      <td>allez</td>\n",
       "      <td>c</td>\n",
       "      <td>est</td>\n",
       "      <td>bon</td>\n",
       "      <td>pour</td>\n",
       "      <td>$TIME$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cible        Mot1 Mot2 Mot3 Mot4  Mot5    Mot6 Mot7   Mot8 Mot9 Mot10\n",
       "0  Confirm          OK  NaN  NaN  NaN   NaN     NaN  NaN    NaN  NaN   NaN\n",
       "1  Confirm  absolument  NaN  NaN  NaN   NaN     NaN  NaN    NaN  NaN   NaN\n",
       "2  Confirm          ah  oui   ça    c   est    bien   ça  comme   ça   NaN\n",
       "3  Confirm       aller  NaN  NaN  NaN   NaN     NaN  NaN    NaN  NaN   NaN\n",
       "4  Confirm       allez    c  est  bon  pour  $TIME$  NaN    NaN  NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../IntroductionDL/calldesk-intents.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.fit(train['Cible'])\n",
    "list(le.classes_)\n",
    "train['Cible'] = le.transform(train['Cible'])\n",
    "\n",
    "#pd.get_dummies\n",
    "train_Mot1 = pd.get_dummies(train['Mot1'])\n",
    "train_Mot2 = pd.get_dummies(train['Mot2'])\n",
    "train_Mot3 = pd.get_dummies(train['Mot3'])\n",
    "train_Mot4 = pd.get_dummies(train['Mot4'])\n",
    "train_Mot5 = pd.get_dummies(train['Mot5'])\n",
    "train_Mot6 = pd.get_dummies(train['Mot6'])\n",
    "train_Mot7 = pd.get_dummies(train['Mot7'])\n",
    "train_Mot8 = pd.get_dummies(train['Mot8'])\n",
    "train_Mot9 = pd.get_dummies(train['Mot9'])\n",
    "train_Mot10 = pd.get_dummies(train['Mot10'])\n",
    "train_new = pd.concat([train,train_Mot1,train_Mot2,train_Mot3,train_Mot4,train_Mot5,train_Mot6,train_Mot7,train_Mot8,train_Mot9,train_Mot10],axis=1)\n",
    "\n",
    "#Suppression des doublons\n",
    "\n",
    "del train_new['Mot1']\n",
    "del train_new['Mot2']\n",
    "del train_new['Mot3']\n",
    "del train_new['Mot4']\n",
    "del train_new['Mot5']\n",
    "del train_new['Mot6']\n",
    "del train_new['Mot7']\n",
    "del train_new['Mot8']\n",
    "del train_new['Mot9']\n",
    "del train_new['Mot10']\n",
    "\n",
    "\n",
    "#del train_new['Finess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cible</th>\n",
       "      <th>$TIME$</th>\n",
       "      <th>OK</th>\n",
       "      <th>a-t-il</th>\n",
       "      <th>absolument</th>\n",
       "      <th>accessible</th>\n",
       "      <th>ah</th>\n",
       "      <th>ajouter</th>\n",
       "      <th>aller</th>\n",
       "      <th>allez</th>\n",
       "      <th>...</th>\n",
       "      <th>prochain</th>\n",
       "      <th>prochains</th>\n",
       "      <th>que</th>\n",
       "      <th>rendez-vous</th>\n",
       "      <th>revoir</th>\n",
       "      <th>s</th>\n",
       "      <th>te</th>\n",
       "      <th>une</th>\n",
       "      <th>voir</th>\n",
       "      <th>vous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cible  $TIME$  OK  a-t-il  absolument  accessible  ah  ajouter  aller  \\\n",
       "0      0       0   1       0           0           0   0        0      0   \n",
       "1      0       0   0       0           1           0   0        0      0   \n",
       "2      0       0   0       0           0           0   1        0      0   \n",
       "3      0       0   0       0           0           0   0        0      1   \n",
       "4      0       0   0       0           0           0   0        0      0   \n",
       "\n",
       "   allez  ...   prochain  prochains  que  rendez-vous  revoir  s  te  une  \\\n",
       "0      0  ...          0          0    0            0       0  0   0    0   \n",
       "1      0  ...          0          0    0            0       0  0   0    0   \n",
       "2      0  ...          0          0    0            0       0  0   0    0   \n",
       "3      0  ...          0          0    0            0       0  0   0    0   \n",
       "4      1  ...          0          0    0            0       0  0   0    0   \n",
       "\n",
       "   voir  vous  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 891 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ah       1\n",
       "oui      1\n",
       "ça       1\n",
       "c        1\n",
       "est      1\n",
       "bien     1\n",
       "ça       1\n",
       "comme    1\n",
       "ça       1\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.iloc[2][train_new.iloc[2]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def kfolds(k,N,seed=None):\n",
    "    random.seed(seed)\n",
    "    out = [ list() for _ in range(k) ]\n",
    "    for n in range(N): out[random.randrange(k)].append(n)\n",
    "    return(out)\n",
    "\n",
    "K = kfolds(seed=42,k=5,N=len(train_new))\n",
    "fold1 = sum(K[1:5],[]) # K[1] + K[2] + K[3] + K[4]\n",
    "#fold1 = K[1]+K[2]+K[3]+K[4]\n",
    "xtrain = train_new.iloc[fold1][train_new.keys()[1:]]\n",
    "ytrain = train_new.iloc[fold1][train_new.keys()[0]]\n",
    "\n",
    "xtest = train_new.iloc[K[0]][train_new.keys()[1:]]\n",
    "ytest = train_new.iloc[K[0]][train_new.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitclf = clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87341772151898733"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitclf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitgbc = gbc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83544303797468356"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitgbc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of nltk to improve the data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nous', 'somm', 'le', 'mond']\n"
     ]
    }
   ],
   "source": [
    "import snowballstemmer\n",
    "\n",
    "stemmer = snowballstemmer.stemmer('french');\n",
    "print(stemmer.stemWords(\"Nous sommes le monde\".split()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word2vec method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create better input for word2vec\n",
    "word2vec.word2phrase(dataf, datapath + \"calldesk-intents-phrases.txt\" , verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Starting training using file ../IntroductionDL/calldesk-intents-phrases.txt\\n'b'Vocab size: 108\\n'b'Words in train file: 6991\\n'"
     ]
    }
   ],
   "source": [
    "word2vec.word2clusters(datapath + \"calldesk-intents-phrases.txt\", datapath + \"calldesk-intents-clusters.txt\", 100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'word2vec' has no attribute 'load_word2vec_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-16a7086a3c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"calldesk-intents-clusters.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'word2vec' has no attribute 'load_word2vec_format'"
     ]
    }
   ],
   "source": [
    "model = word2vec.load_word2vec_format(datapath + \"calldesk-intents-clusters.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "nce_weights = tf.Variable(\n",
    "  tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                      stddev=1.0 / math.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x104431860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
